# Introduction to Google Cloud Data Loss Prevention
​	Google DLP solution landscape refers to the tools that is used to protect PII and sensitive data lying in cloud storages, databases and can even be expanded to inspect on-premise database as well. The blog article relates to summarize the Google DLP platform in minimal words and familiarize with Cloud DLP terminology and try to provide the best working examples. 
## Infotypes, Likelihood and Fine-Tuning
#### Built-In Infotype Detectors
​	There are over 120 ***[built-in Infotype detectors](https://cloud.google.com/dlp/docs/concepts-infotypes#built-in).***  They include detectors for country- or region-specific sensitive data types as well as globally applicable data types.  Cloud DLP Infotype detection leverages various techniques **including pattern matching, checksums, machine-learning, context analysis, and others.** Some example Infotypes are listed below. For the complete list click ***[here](https://cloud.google.com/dlp/docs/infotypes-reference)***
###### Country- or region-specific sensitive data types 
- *French* *Numéro d'Inscription au Répertoire (NIR)* (`FRANCE_NIR`)
- UK driver's license number (`UK_DRIVERS_LICENSE_NUMBER`)
- US Social Security number (`US_SOCIAL_SECURITY_NUMBER`)
- India Aadhar Number (`INDIA_AADHAAR_INDIVIDUAL`)
###### *Globally applicable data types* 
- Person name (`PERSON_NAME`)
- Telephone numbers (`PHONE_NUMBER`)
- Email addresses (`EMAIL_ADDRESS`)
- Credit card numbers (`CREDIT_CARD_NUMBER`)
#### Custom InfoType Detectors
These are detectors that you create yourself. There are three kinds of ***[custom infoType detectors](https://cloud.google.com/dlp/docs/concepts-infotypes#custom):***
- [***Small custom dictionary detectors***](https://cloud.google.com/dlp/docs/concepts-infotypes#small) are simple word lists that Cloud DLP matches on. Use small custom dictionary detectors when you have a list of up to ***several tens of thousands of words or phrases***. Small custom dictionary detectors are preferred if you don't anticipate your word list changing significantly.
- ***[Large custom dictionary detectors](https://cloud.google.com/dlp/docs/concepts-infotypes#large)*** are generated by Cloud DLP using large lists of words or phrases stored in either ***Cloud Storage or BigQuery***. Use large custom dictionary detectors when you have a large list of words or phrases—***up to tens of millions.***
- ***[Regular expressions (regex) detectors](https://cloud.google.com/dlp/docs/concepts-infotypes#regex)*** enable Cloud DLP to detect matches based on a regular expression pattern.
#### Likelihood
​	Results are categorized into buckets based on how likely they are to represent a match with a certainty score called likelihood. For example, a Infotype may return a lower likelihood if it only matches the pattern and return a higher likelihood if it matches the pattern and has positive context around it. For this reason, ***<u>you may notice that a single finding could match several types at lower likelihood.</u>***  
The likelihood buckets are `LIKELIHOOD_UNSPECIFIED`*[Default value; =~ POSSIBLE]*,`VERY_UNLIKELY`, `UNLIKELY` , `POSSIBLE`, `LIKELY`, `VERY_LIKELY`
> Note: ***Positive context*** is when the inclusion of certain characters, words, or phrases in proximity to a potentially matched pattern indicates to Cloud DLP that a match to the pattern is more likely. Similarly, ***negative context*** is when the inclusion of certain characters, words, or phrases in proximity to a pattern indicates that a match is less likely.
#### Google DLP Live Demo
​	For a live demo of Google Cloud DLP in action, click below **[link](https://cloud.google.com/dlp/demo/#!/)**. It shows a running demo of **Free From Text Inspection** with **likelihood** for the **built-in Infotypes**, as discussed above. You can select the **INFOTYPES** available and **Likelihood filter** under **Options**
<img src="https://raw.githubusercontent.com/sarath-mec/smks-docker-hdp/master/screenshots/image-20201204100055627.png" alt="image-20201204100055627" style="zoom: 50%;" />
#### Fine-Tuning
​	In addition, Cloud DLP includes inspection rules, which enable you to fine-tune scan results by adding the following to existing built-in or custom infoType detector
- [Exclusion rules](https://cloud.google.com/dlp/docs/concepts-infotypes#exclusion) : Rules that enable you to decrease the number of findings returned.
- [Hotword rules](https://cloud.google.com/dlp/docs/concepts-infotypes#hotword) : Rules that enable you to increase the quantity or change the likelihood value of findings returned. 
## Supported File Types
Even though these below terms are confusing, it is interchangeably used, which will be clear once you start experimenting the features.
#### De-identify
​	De-identify is generally used as a term to transform sensitive text in your data. The De-identify transformation methods available are discussed **later in this blog**. There are generally two types of Text De-identification Transformation
- [InfoTypeTransformations](https://cloud.google.com/dlp/docs/deidentify-sensitive-data#infotype_transformations): Applied to values within **submitted free-form text** that are identified as a specific infoType.
- [RecordTransformations](https://cloud.google.com/dlp/docs/deidentify-sensitive-data#record_transformations): Applied to values within **submitted tabular text data** that are identified as a specific infoType, or on an entire column of tabular data.
#### Redaction
​	Redaction is generally used as a term to remove sensitive data.
  - [Redacting sensitive data from text](https://cloud.google.com/dlp/docs/redacting-sensitive-data) : It returns the string with any sensitive data replaced by your chosen placeholder.
  - [Redacting sensitive data from images](https://cloud.google.com/dlp/docs/redacting-sensitive-data-images) : Google runs **Optical Character Recognition** to identify Infotypes, even **handwritten** text and redact them as shown in example
  - [Redacting Rows through Record Suppression](https://cloud.google.com/dlp/docs/deidentify-sensitive-data#record_transformations):  We can define Record Suppression Rules for RecordTransformations, by which sensitive records are removed from result
For more details about other supported formats like PDFs, Images, AVRO, CSV and the Scan Methods used click **[here](https://cloud.google.com/dlp/docs/supported-file-types)**
> *Note: Some format not available right now are excel, parquet, ORC etc*
## DLP Code Execution
​	The lowest level of executing DLP **(metric for DLP billing also)** is by **[invoking REST APIs for a specific task.](https://cloud.google.com/dlp/docs/quickstart-json)**  The REST APIs available are mentioned **[here](https://cloud.google.com/dlp/docs/apis)**.  There are various [Client Libraries](https://cloud.google.com/dlp/docs/libraries) available to invoke Cloud DLP API's in languages like C#, Go, Java, Node.js, PHP, Python, Ruby. 
- **[Node.js DLP Github](https://github.com/googleapis/nodejs-dlp)** : **Node.js** seems to be the popular and well maintained. 
- [Python DLP Github](https://github.com/googleapis/python-dlp)
- [Go DLP Github](https://github.com/googleapis/google-cloud-go) : Part of the Complete Go Google API GitHub Project
- [Java DLP GitHub](https://github.com/googleapis/java-dlp)
- [Ruby DLP Github](https://github.com/googleapis/google-cloud-ruby/blob/master/google-cloud-dlp/README.md) : Part of the Complete Ruby Google API GitHub Project
- [PHP DLP Github](https://github.com/googleapis/google-cloud-php-dlp)
- [Dotnet C# Github](https://github.com/GoogleCloudPlatform/dotnet-docs-samples/tree/master/dlp/api)  : Part of the Complete Ruby Google API GitHub Project
#### Notes
- The above Client library is useful for integrating into existing web applications or Custom Data Pipeline code.
- In addition to the above Client Libraries, Google Cloud DLP Inspection jobs, can be run and scheduled from the Console discussed below.
- Google DLP is integrated to other products like **Google Data Fusion** connectors. Refer the [Qwiklabs tutorial](https://www.qwiklabs.com/focuses/12373?catalog_rank=%7B%22rank%22%3A1%2C%22num_filters%22%3A0%2C%22has_search%22%3Atrue%7D&parent=catalog&search_id=8100528) for more info
#### Google Dataflow DLP Templates
​	Dataflow is a managed service for executing a wide variety of data processing patterns, based on Apache Beam Framework. For Continuous and Batch pipelines, Google Recommended way is to develop using **[Google DataFlow](https://cloud.google.com/dataflow)**. 
There are many existing Google Dataflow Templates available, which can customized for our specific use case. Some of the examples are
- [De-identification and re-identification of PII in large-scale datasets using Cloud DLP and Dataflow](https://cloud.google.com/solutions/de-identification-re-identification-pii-using-cloud-dlp)
- [Relational Database Import to Big Query with Dataflow and DLP API](https://github.com/GoogleCloudPlatform/dlp-rdb-bq-import)
- [Google Dataflow Template for Data Masking/Tokenization from Cloud Storage to BigQuery (using Cloud DLP)](https://cloud.google.com/dataflow/docs/guides/templates/provided-streaming#data-maskingtokenization-from-cloud-storage-to-bigquery-using-cloud-dlp)
## Data Loss Prevention Console 
Google DLP recently introduced DLP Console under **Security -> Data Loss Prevention.** 
*Note: We need to enable Cloud Data Loss Prevention (DLP) API in your project. If not it will be prompted*
Here we can directly run DLP jobs which was earlier achieved through backend APIs. The Console also provides the JSON representation of Templates, which was earlier used to invoke the APIs.  Dataflow is a managed service for executing a wide variety of data processing patterns
 <img src="https://raw.githubusercontent.com/sarath-mec/smks-docker-hdp/master/screenshots/image-20201203010629031-new.png" alt="image-20201203010629031-new" style="zoom:67%;" />
- ##### [Inspection Jobs](https://cloud.google.com/dlp/docs/creating-job-triggers)
  This can be used to inspect data in
  - Google Cloud Storage
  - Google BigQuery
  - Google Cloud Datastore
- ##### [Re-identification risk analysis Jobs](https://cloud.google.com/dlp/docs/concepts-risk-analysis)
  Process of analyzing sensitive data to find properties that might increase the risk of subjects being identified, or of sensitive information about individuals being revealed. You can use risk analysis methods before de-identification to help determine an effective de-identification strategy, or after de-identification to monitor for any changes or outliers. This is **more advanced concept** and will be discussed in subsequent blogs.
  - k-anonymity
  - l-diversity
  - k-map
  - δ-presence
- ##### [Templates](https://cloud.google.com/dlp/docs/concepts-templates)
  Useful for decoupling and store configuration information in a single place —like what you inspect for or de-identify—from the implementation of your requests. Once you define a template, we can reuse the template to inspect or re-identify data, in the jobs as well as in APIs
  - [Inspection Templates](https://cloud.google.com/dlp/docs/quickstart-create-template-inspect)
      Templates for persisting configuration information for inspection scan jobs, including what predefined or custom detectors to use. 
  - [De-identification Templates](https://cloud.google.com/dlp/docs/creating-templates-deid) 
      Templates for saving configuration information for de-identification jobs, including both **infoType** and **record (structured dataset)** transformations. Even though the above link suggests creating template from backend, we can create the same from front-end UI as well. This will be disused in detail in our first use case
- ##### [Stored Infotype](https://cloud.google.com/dlp/docs/creating-stored-infotypes)
  This is used to create Custom InfoType Detectors, as mentioned above including small custom dictionary, large custom dictionary and regular expression detectors
- ##### [Available actions for DLP Jobs](https://cloud.google.com/dlp/docs/concepts-actions)
  Cloud DLP supports different types of actions depending on the type of job being run (inspection or risk analysis scan jobs). Following are the currently supported actions:
  - **Save findings to BigQuery** (inspection and risk jobs)
  - **Publish to Pub/Sub** (inspection and risk jobs)
  - **Publish to Security Command Center** (risk jobs)
  - **Publish to Data Catalog** (risk jobs): Google Cloud's metadata management service.
  - **Publish to Google Cloud's operations suite** (risk jobs)
  - **Notify by email** (inspection and risk jobs)
## De-identify Transformation Techniques
"De-identify", the term is sometimes confusing and is the general bucket of activities possible below often referred as mask/redact,obfuscate etc..
  > Note: There is a term **"re-identify",** which refers to Google DLP option to extract the original value which has been encrypted using Pseudonymization technique
The **<u>*[De-identify Transformation Techniques](https://cloud.google.com/dlp/docs/transformations-reference)*</u>** available are
- [Redaction](https://cloud.google.com/dlp/docs/transformations-reference#redaction): Deletes all or part of a detected sensitive value.
```
Input : My name is Alicia Abernathy, and my email address is aabernathy@example.com.
Output: My name is Alicia Abernathy, and my email address is .
```
- [Replacement](https://cloud.google.com/dlp/docs/transformations-reference#replacement): Replaces a detected sensitive value with a specified surrogate value.
```
Input : My name is Alicia Abernathy, and my email address is aabernathy@example.com.
Output: My name is Alicia Abernathy, and my email address is [fake@example.com].
```
- [Masking](https://cloud.google.com/dlp/docs/transformations-reference#masking): Replaces a number of characters of a sensitive value with a specified surrogate character, such as a hash (#) or asterisk (*).
```
Input : My name is Alicia Abernathy, and my email address is aabernathy@example.com.
Output: My name is Alicia Abernathy, and my email address is ##########@#######.###.
```
- [Crypto-based tokenization/Pseudonymization](https://cloud.google.com/dlp/docs/pseudonymization): Encrypts the original sensitive data value using a cryptographic key. Cloud DLP supports several types of tokenization, including transformations that can be reversed, or "re-identified.". **This is a separate topic which will be discussed below**
- [Bucketing](https://cloud.google.com/dlp/docs/concepts-bucketing): "Generalizes" a sensitive value by replacing it with a range of values. (For example, replacing a specific age with an age range, or temperatures with ranges corresponding to "Hot," "Medium," and "Cold.")
- [Date shifting](https://cloud.google.com/dlp/docs/concepts-date-shifting): Shifts sensitive date values by a random amount of time. Shifting dates is usually done in context to an individual or an entity.
- [Time extraction](https://cloud.google.com/dlp/docs/transformations-reference#time_extraction): Extracts or preserves specified portions of date and time values.
## Crypto-based tokenization/Pseudonymization
**[Pseudonymization](https://cloud.google.com/dlp/docs/pseudonymization)** is a de-identification technique that replaces sensitive data values with cryptographically generated *tokens*. 
These are generally used in use cases like
- **Re-identify/Reverse** the Original value if we have the original key and secret. 
- Maintain **referential integrity** of values, if used to de-identify foreign key/primary key columns in tables. This will ensure that joins would work as expected
- **Format preserving encryption** By design, both the **character set and the length of the input value are preserved** in the output value. 
- ***Surrogate annotation*** is the process of appending leading characters, used to understand the information stored in the encrypted form. Say for eg CC will be appended at the start of the encrypted value to show that it is an encrypted credit card number value.
- ***Cryptographic hashed*** values cannot be reversed, even though it maintains referential integrity. Also surrogate annotation is also not supported in the API
- **Context tweak:** A reference to a data field that "tweaks" the input value so that identical input values can be de-identified to different output values. The context tweak is optional when transforming a column of structured, or tabular data, with a `RecordTransformation`. 
- We have to use **DLP APIs programmatically** to reidentify the original data once encrypted using original key and secret
- Cloud DLP supports three techniques as below. 

These methods are summarized in the following table.

| ** Deterministic encryption using AES-SIV** | **Format preserving encryption**                    | **Cryptographic hashing**                                    |                                                     |
| :------------------------------------------ | :-------------------------------------------------- | :----------------------------------------------------------- | --------------------------------------------------- |
| **Encryption type**                         | [AES-SIV](https://tools.ietf.org/html/rfc5297)      | [FPE-FFX](https://en.wikipedia.org/wiki/Format-preserving_encryption) | [HMAC-SHA-256](https://tools.ietf.org/html/rfc4634) |
| **Supported input values**                  | At least 1 char long; no character set limitations. | At least 2 chars long; must be encoded as ASCII.             | Must be a string or an integer value.               |
| **Surrogate annotation**                    | Optional.                                           | Optional.                                                    | N/A                                                 |
| **Context tweak**                           | Optional.                                           | Optional.                                                    | N/A                                                 |
| **Character set and length preserved**      | ✗                                                   | ✓                                                            | ✗                                                   |
| **Reversible**                              | ✓                                                   | ✓                                                            | ✗                                                   |
| **Referential integrity**                   | ✓                                                   | ✓                                                            | ✓                                                   |


## **Pricing**
Cloud DLP content method pricing is billed based on bytes inspected, transformed. Price per GB is around 2-3 Dollars. Please see **[here](https://cloud.google.com/dlp/pricing)** for more details
##### [Keeping Costs Under Control](https://cloud.google.com/dlp/docs/best-practices-costs)
- Use sampling to restrict the number of bytes inspected
- Scan only data that has changed
- Limit scans of files in Cloud Storage to only relevant files
